# CivilservantExam-Chat  å…¬åŠ¡å‘˜è€ƒè¯•å¤§æ¨¡å‹

<div align="center">

<img src="./assets/logo.png" width="200"/>
  <div align="center">
    <b><font size="5">CivilservantExam-Chat</font></b>
  </div>

[ğŸ¤—HuggingFace][HuggingFace_Model-url]

[HuggingFace_Model-url]: https://modelscope.cn/models/yangchanghui/civil-exam-internlm2-chat-7B/summary

## ğŸ“– ç®€ä»‹

CivilservantExam chat æ˜¯ä¸€ä¸ªé›†æˆäº†å…¬åŠ¡å‘˜è€ƒè¯•è¯•é¢˜åŠå…¶è§£ç­”çš„å¤§è¯­è¨€æ¨¡å‹ã€‚è¯¥æ¨¡å‹ç›®å‰ä»…ä½¿ç”¨å…¬å¼€çš„å…¬åŠ¡å‘˜è€ƒè¯•è¯•é¢˜æ•°æ®é›†[COIG](https://link.zhihu.com/?target=https%3A//huggingface.co/datasets/BAAI/COIG)ï¼ŒåŸºäº InternLM2-Math-7B æ¨¡å‹ï¼Œé€šè¿‡ xtuner å¾®è°ƒï¼Œä¸“é—¨è®¾è®¡ç”¨äºè§£ç­”å…¬åŠ¡å‘˜è€ƒè¯•é—®é¢˜ã€‚ç›®å‰ä½¿ç”¨çš„æ•°æ®é›†æœ‰é™ï¼Œåç»­ä¼šå°è¯•åŠ å…¥æ›´å¤šçš„æ•°æ®é›†ï¼Œä»¥æå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

å¦‚æœä½ è§‰å¾—è¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œæ¬¢è¿ â­ Starï¼Œè®©æ›´å¤šçš„äººå‘ç°å®ƒï¼

## ğŸ“‘ æ•°æ®é›†å‡†å¤‡

### 1. ä¸‹è½½æ•°æ®é›†
[COIG](https://link.zhihu.com/?target=https%3A//huggingface.co/datasets/BAAI/COIG)

### 2. æ•°æ®é¢„å¤„ç†

æ•°æ®é›†æ ¼å¼ï¼š
[dataset_format](https://github.com/InternLM/xtuner/blob/main/docs/zh_cn/user_guides/dataset_format.md)
æ•°æ®å‡†å¤‡:
[dataset_prepare](https://github.com/InternLM/xtuner/blob/main/docs/zh_cn/user_guides/dataset_prepare.md)


#### ğŸš€ XTunerå¾®è°ƒ

1. å‡†å¤‡é…ç½®æ–‡ä»¶

```bash
# åˆ—å‡ºæ‰€æœ‰å†…ç½®é…ç½®
xtuner list-cfg

mkdir /root/civil-exam/config && cd /root/civil-exam/config

xtuner copy-cfg internlm2_chat_7b_qlora_oasst1_e3 .
```

2. æ¨¡å‹ä¸‹è½½

```bash
mkdir -p /root/civil-exam/model
```
`download.py`

```python
import torch
from modelscope import snapshot_download, AutoModel, AutoTokenizer
import os
model_dir = snapshot_download('yangchanghui/civil-exam-internlm2-chat-7B', cache_dir='/root/civil-exam/model')
```


3. ä¿®æ”¹é…ç½®æ–‡ä»¶

```bash
cd /root/civil-exam/config
vim internlm2_chat_7b_qlora_oasst1_e3_copy.py
```

```python
# ä¿®æ”¹æ¨¡å‹ä¸ºæœ¬åœ°è·¯å¾„
- pretrained_model_name_or_path = 'internlm/internlm-chat-7b'
+ pretrained_model_name_or_path = '/root/civil-exam/model/civil-exam-internlm2-chat-7B'

# ä¿®æ”¹è®­ç»ƒæ•°æ®é›†ä¸ºæœ¬åœ°è·¯å¾„
- data_path = 'timdettmers/openassistant-guanaco'
+ data_path = '/root/civil-exam/exam_instructions_inernlm.jsonl'
- dataset=dict(type=load_dataset, path=data_path)

+ dataset=dict(
+       type=load_dataset, path='json', data_files=dict(train=data_path))

- dataset=dict(type=load_dataset, path=data_path)
+ dataset=dict(
+       type=load_dataset, path='json', data_files=dict(train=data_path))
```


4. å¼€å§‹å¾®è°ƒ

```bash
cd ..
xtuner train /root/civil-exam/config/internlm2_chat_7b_qlora_oasst1_e3_copy.py --deepspeed deepspeed_zero2
```

5. PTH æ¨¡å‹è½¬æ¢ä¸º HuggingFace æ¨¡å‹

```bash
mkdir /root/civil-exam/model/hf
xtuner convert pth_to_hf /root/civil-exam/config/internlm2_chat_7b_qlora_oasst1_e3_copy.py \
                         ./work_dirs/internlm2_chat_7b_qlora_oasst1_e3_copy/epoch_3.pth \
                         /root/civil-exam/model/hf
```

6. HuggingFace æ¨¡å‹åˆå¹¶åˆ°å¤§è¯­è¨€æ¨¡å‹
```bash
export MKL_SERVICE_FORCE_INTEL=1
export MKL_THREADING_LAYER='GNU'

# åŸå§‹æ¨¡å‹å‚æ•°å­˜æ”¾çš„ä½ç½®
export NAME_OR_PATH_TO_LLM=/root/civil-exam/model/Shanghai_AI_Laboratory/internlm2-chat-7b

# Hugging Faceæ ¼å¼å‚æ•°å­˜æ”¾çš„ä½ç½®
export NAME_OR_PATH_TO_ADAPTER=/root/civil-exam/model/hf

# æœ€ç»ˆMergeåçš„å‚æ•°å­˜æ”¾çš„ä½ç½®
mkdir /root/civil-exam/model/hf_merge
export SAVE_PATH=/root/civil-exam/model/hf_merge

# æ‰§è¡Œå‚æ•°Merge
xtuner convert merge \
    $NAME_OR_PATH_TO_LLM \
    $NAME_OR_PATH_TO_ADAPTER \
    $SAVE_PATH \
    --max-shard-size 2GB
```

å…·ä½“æ­¥éª¤ï¼š
[incremental_pretraining](https://github.com/InternLM/xtuner/blob/main/docs/zh_cn/user_guides/incremental_pretraining.md)

7. Demo

å¾®è°ƒå‰:
<p align="center">
    <img src="assets/xtuner_pre.png" alt="Demo" width="100%">
</p>


å¾®è°ƒåï¼š
<p align="center">
    <img src="assets/xtuner_post.png" alt="Demo" width="100%">
</p>

- CivilservantExam-Chat ä¸ InternLM2-Math-7B å¯¹äºåŒä¸€é“å…¬åŠ¡å‘˜è¯•é¢˜çš„å›ç­”ä¸­ï¼š 
  CivilservantExam å›ç­”æ­£ç¡®ï¼ŒInternLM2-Math-7B å›ç­”é”™è¯¯ã€‚

### ç‰¹åˆ«é¸£è°¢

<div align="center">

***æ„Ÿè°¢ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤ç»„ç»‡çš„ ä¹¦ç”ŸÂ·æµ¦è¯­å®æˆ˜è¥ å­¦ä¹ æ´»åŠ¨~***

***æ„Ÿè°¢ OpenXLab å¯¹é¡¹ç›®éƒ¨ç½²çš„ç®—åŠ›æ”¯æŒ~***

***æ„Ÿè°¢ æµ¦è¯­å°åŠ©æ‰‹ å¯¹é¡¹ç›®çš„æ”¯æŒ~***

***æ„Ÿè°¢ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤æ¨å‡ºçš„ä¹¦ç”ŸÂ·æµ¦è¯­å¤§æ¨¡å‹å®æˆ˜è¥ï¼Œä¸ºæˆ‘ä»¬çš„é¡¹ç›®æä¾›å®è´µçš„æŠ€æœ¯æŒ‡å¯¼å’Œå¼ºå¤§çš„ç®—åŠ›æ”¯æŒï¼***

[**InternLM-tutorial**](https://github.com/InternLM/tutorial)ã€[**InternStudio**](https://studio.intern-ai.org.cn/)ã€[**xtuner**](https://github.com/InternLM/xtuner)ã€[**AMchat**](https://github.com/AXYZdong/AMchat/tree/main)

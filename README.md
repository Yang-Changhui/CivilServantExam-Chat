# CivilservantExam-Chat  å…¬åŠ¡å‘˜è€ƒè¯•å¤§æ¨¡å‹

<div align="center">

<img src="./assets/logo.png" width="200"/>
  <div align="center">
    <b><font size="5">CivilservantExam-Chat</font></b>
  </div>

[<img src="./assets/modelscope_logo.png" width="20px" /> ModelScope][ModelScope-url]

[ModelScope-url]: https://modelscope.cn/models/yangchanghui/civil-exam-internlm2-chat-7B/summary

</div>

## ğŸ“– ç®€ä»‹

CivilservantExam chat æ˜¯ä¸€ä¸ªé›†æˆäº†å…¬åŠ¡å‘˜è€ƒè¯•è¯•é¢˜åŠå…¶è§£ç­”çš„å¤§è¯­è¨€æ¨¡å‹ã€‚è¯¥æ¨¡å‹ç›®å‰ä»…ä½¿ç”¨å…¬å¼€çš„å…¬åŠ¡å‘˜è€ƒè¯•è¯•é¢˜æ•°æ®é›†[COIG](https://link.zhihu.com/?target=https%3A//huggingface.co/datasets/BAAI/COIG)ï¼ŒåŸºäº InternLM2-Math-7B æ¨¡å‹ï¼Œé€šè¿‡ xtuner å¾®è°ƒï¼Œä¸“é—¨è®¾è®¡ç”¨äºè§£ç­”å…¬åŠ¡å‘˜è€ƒè¯•é—®é¢˜ã€‚ç›®å‰ä½¿ç”¨çš„æ•°æ®é›†æœ‰é™ï¼Œåç»­ä¼šå°è¯•åŠ å…¥æ›´å¤šçš„æ•°æ®é›†ï¼Œä»¥æå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

å¦‚æœä½ è§‰å¾—è¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œæ¬¢è¿ â­ Starï¼Œè®©æ›´å¤šçš„äººå‘ç°å®ƒï¼

## ğŸ“‘ æ•°æ®é›†å‡†å¤‡

### 1. ä¸‹è½½æ•°æ®é›†
[COIG](https://link.zhihu.com/?target=https%3A//huggingface.co/datasets/BAAI/COIG)

### 2. æ•°æ®é¢„å¤„ç†

æ•°æ®é›†æ ¼å¼:
[dataset_format](https://github.com/InternLM/xtuner/blob/main/docs/zh_cn/user_guides/dataset_format.md)

æ•°æ®å‡†å¤‡: 
[dataset_prepare](https://github.com/InternLM/xtuner/blob/main/docs/zh_cn/user_guides/dataset_prepare.md)


## ğŸš€ XTunerå¾®è°ƒ

1. å‡†å¤‡é…ç½®æ–‡ä»¶

```bash
# åˆ—å‡ºæ‰€æœ‰å†…ç½®é…ç½®
xtuner list-cfg

mkdir /root/civil-exam/config && cd /root/civil-exam/config

xtuner copy-cfg internlm2_chat_7b_qlora_oasst1_e3 .
```

2. æ¨¡å‹ä¸‹è½½

```bash
mkdir -p /root/civil-exam/model
mkdir download.py
```

```python
import torch
from modelscope import snapshot_download, AutoModel, AutoTokenizer
import os
model_dir = snapshot_download('yangchanghui/civil-exam-internlm2-chat-7B', cache_dir='/root/civil-exam/model')
```


3. ä¿®æ”¹é…ç½®æ–‡ä»¶

```bash
cd /root/civil-exam/config
vim internlm2_chat_7b_qlora_oasst1_e3_copy.py
```

```python
# ä¿®æ”¹æ¨¡å‹ä¸ºæœ¬åœ°è·¯å¾„
- pretrained_model_name_or_path = 'internlm/internlm-chat-7b'
+ pretrained_model_name_or_path = '/root/civil-exam/model/civil-exam-internlm2-chat-7B'

# ä¿®æ”¹è®­ç»ƒæ•°æ®é›†ä¸ºæœ¬åœ°è·¯å¾„
- data_path = 'timdettmers/openassistant-guanaco'
+ data_path = '/root/civil-exam/exam_instructions_inernlm.jsonl'
- dataset=dict(type=load_dataset, path=data_path)

+ dataset=dict(
+       type=load_dataset, path='json', data_files=dict(train=data_path))

- dataset=dict(type=load_dataset, path=data_path)

-   template_map_fn=dict(
-       type=template_map_fn_factory, template=prompt_template),
+   template_map_fn=None,
```


4. å¼€å§‹å¾®è°ƒ

```bash
cd ..
xtuner train /root/civil-exam/config/internlm2_chat_7b_qlora_oasst1_e3_copy.py --deepspeed deepspeed_zero2
```

#### å¾®è°ƒæ³¨æ„äº‹é¡¹
- æ•°æ®é›†çš„è´¨é‡é—®é¢˜å¯¹æ¨¡å‹çš„å¾®è°ƒè‡³å…³é‡è¦ï¼Œåœ¨å¤„ç†æ•°æ®é›†æ—¶å¯ä»¥å°†å…¶ä¸­å¤šä½™çš„ç©ºæ ¼ã€\tã€\nç­‰ç¬¦å·åˆ é™¤ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œæ›¿æ¢ã€‚
- å¾®è°ƒæ—¶ï¼Œæ•°æ®é‡å°‘çš„æƒ…å†µä¸‹å¾ˆå®¹æ˜“è¿‡æ‹Ÿåˆï¼Œå› æ­¤åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®evaluation_inputsï¼Œå¦‚æœæ£€æµ‹ç»“æœç¬¦åˆé¢„æœŸçš„æ—¶å€™ï¼Œå°±å°½é‡åœæ­¢è®­ç»ƒã€‚

è¦è§£å†³è¿‡æ‹Ÿåˆï¼Œå‚è€ƒå‰‘é”‹å¤§ä½¬çš„æ„è§ï¼Œ
å‡å¦‚æˆ‘ä»¬æƒ³è¦è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå…¶å®å¯ä»¥é€šè¿‡ä»¥ä¸‹ä¸¤ä¸ªæ–¹å¼è§£å†³ï¼š

**å‡å°‘ä¿å­˜æƒé‡æ–‡ä»¶çš„é—´éš”å¹¶å¢åŠ æƒé‡æ–‡ä»¶ä¿å­˜çš„ä¸Šé™**ï¼šè¿™ä¸ªæ–¹æ³•å®é™…ä¸Šå°±æ˜¯é€šè¿‡é™ä½é—´éš”ç»“åˆè¯„ä¼°é—®é¢˜çš„ç»“æœï¼Œä»è€Œæ‰¾åˆ°æœ€ä¼˜çš„æƒé‡ã€‚æˆ‘ä»¬å¯ä»¥æ¯éš”100ä¸ªæ‰¹æ¬¡æ¥çœ‹ä»€ä¹ˆæ—¶å€™æ¨¡å‹å·²ç»å­¦åˆ°äº†è¿™éƒ¨åˆ†çŸ¥è¯†ä½†æ˜¯è¿˜ä¿ç•™ç€åŸºæœ¬çš„å¸¸è¯†ï¼Œä»€ä¹ˆæ—¶å€™å·²ç»è¿‡æ‹Ÿåˆä¸¥é‡åªä¼šè¯´ä¸€å¥è¯äº†ã€‚ä½†æ˜¯ç”±äºå†é…ç½®æ–‡ä»¶æœ‰è®¾ç½®æƒé‡æ–‡ä»¶ä¿å­˜æ•°é‡çš„ä¸Šé™ï¼Œå› æ­¤åŒæ—¶å°†è¿™ä¸ªä¸Šé™åŠ å¤§ä¹Ÿæ˜¯éå¸¸å¿…è¦çš„ã€‚

**å¢åŠ å¸¸è§„çš„å¯¹è¯æ•°æ®é›†ä»è€Œç¨€é‡ŠåŸæœ¬æ•°æ®çš„å æ¯”**ï¼šè¿™ä¸ªæ–¹æ³•å…¶å®å°±æ˜¯å¸Œæœ›æˆ‘ä»¬æ­£å¸¸ç”¨å¯¹è¯æ•°æ®é›†åšæŒ‡ä»¤å¾®è°ƒçš„åŒæ—¶è¿˜åŠ ä¸Šä¸€éƒ¨åˆ†çš„æ•°æ®é›†æ¥è®©æ¨¡å‹æ—¢èƒ½å¤Ÿå­¦åˆ°æ­£å¸¸å¯¹è¯ï¼Œä½†æ˜¯åœ¨é‡åˆ°ç‰¹å®šé—®é¢˜æ—¶è¿›è¡Œç‰¹æ®ŠåŒ–å¤„ç†ã€‚


5. PTH æ¨¡å‹è½¬æ¢ä¸º HuggingFace æ¨¡å‹

```bash
mkdir /root/civil-exam/model/hf
xtuner convert pth_to_hf /root/civil-exam/config/internlm2_chat_7b_qlora_oasst1_e3_copy.py \
                         ./work_dirs/internlm2_chat_7b_qlora_oasst1_e3_copy/epoch_3.pth \
                         /root/civil-exam/model/hf
```

6. HuggingFace æ¨¡å‹åˆå¹¶åˆ°å¤§è¯­è¨€æ¨¡å‹
```bash
export MKL_SERVICE_FORCE_INTEL=1
export MKL_THREADING_LAYER='GNU'

# åŸå§‹æ¨¡å‹å‚æ•°å­˜æ”¾çš„ä½ç½®
export NAME_OR_PATH_TO_LLM=/root/civil-exam/model/Shanghai_AI_Laboratory/internlm2-chat-7b

# Hugging Faceæ ¼å¼å‚æ•°å­˜æ”¾çš„ä½ç½®
export NAME_OR_PATH_TO_ADAPTER=/root/civil-exam/model/hf

# æœ€ç»ˆMergeåçš„å‚æ•°å­˜æ”¾çš„ä½ç½®
mkdir /root/civil-exam/model/hf_merge
export SAVE_PATH=/root/civil-exam/model/hf_merge

# æ‰§è¡Œå‚æ•°Merge
xtuner convert merge \
    $NAME_OR_PATH_TO_LLM \
    $NAME_OR_PATH_TO_ADAPTER \
    $SAVE_PATH \
    --max-shard-size 2GB
```

å…·ä½“æ­¥éª¤ï¼š
[incremental_pretraining](https://github.com/InternLM/xtuner/blob/main/docs/zh_cn/user_guides/incremental_pretraining.md)

7. Demo

å¾®è°ƒå‰:
<p align="center">
    <img src="assets/xtuner_pre.png" alt="Demo" width="100%">
</p>


å¾®è°ƒåï¼š
<p align="center">
    <img src="assets/xtuner_post.png" alt="Demo" width="100%">
</p>

- CivilservantExam-Chat ä¸ InternLM2-Math-7B å¯¹äºåŒä¸€é“å…¬åŠ¡å‘˜è¯•é¢˜çš„å›ç­”ä¸­ï¼š 
  CivilservantExam å›ç­”æ­£ç¡®ï¼ŒInternLM2-Math-7B å›ç­”é”™è¯¯ã€‚

### ç‰¹åˆ«é¸£è°¢

<div align="center">

***æ„Ÿè°¢ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤ç»„ç»‡çš„ ä¹¦ç”ŸÂ·æµ¦è¯­å®æˆ˜è¥ å­¦ä¹ æ´»åŠ¨~***

***æ„Ÿè°¢ OpenXLab å¯¹é¡¹ç›®éƒ¨ç½²çš„ç®—åŠ›æ”¯æŒ~***

***æ„Ÿè°¢ æµ¦è¯­å°åŠ©æ‰‹ å¯¹é¡¹ç›®çš„æ”¯æŒ~***

***æ„Ÿè°¢ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤æ¨å‡ºçš„ä¹¦ç”ŸÂ·æµ¦è¯­å¤§æ¨¡å‹å®æˆ˜è¥ï¼Œä¸ºæˆ‘ä»¬çš„é¡¹ç›®æä¾›å®è´µçš„æŠ€æœ¯æŒ‡å¯¼å’Œå¼ºå¤§çš„ç®—åŠ›æ”¯æŒï¼***

[**InternLM-tutorial**](https://github.com/InternLM/tutorial)ã€[**InternStudio**](https://studio.intern-ai.org.cn/)ã€[**xtuner**](https://github.com/InternLM/xtuner)ã€[**AMchat**](https://github.com/AXYZdong/AMchat/tree/main)
